{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f894a4c1-9f5b-4011-a03d-ea963322766d",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b91fcf-e4a9-4f5d-9f4d-95ec31e00ebc",
   "metadata": {},
   "source": [
    "This notebook demonstrates a simple text preprocessing pipeline using the [Natural Language Toolkit (NLTK)](https://www.nltk.org/index.html). \n",
    "\n",
    "Make sure you first follow the [instructions on Wattle](https://wattlecourses.anu.edu.au/mod/page/view.php?id=2683737) to set up your environment for this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cae73d-a4a7-48b2-af42-f39310bb9f8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7f1a746-d6a2-4fdd-be1e-969fd31a0353",
   "metadata": {},
   "source": [
    "Raw text from [this Wikipedia page](https://en.wikipedia.org/wiki/Australia)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d5bd45-0578-450a-bfab-3397b710cd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text = \"Australia, officially the Commonwealth of Australia, is a sovereign country comprising the mainland of the Australian continent, the island of Tasmania, and numerous smaller islands. With an area of 7,617,930 square kilometres (2,941,300 sq mi), Australia is the largest country by area in Oceania and the world's sixth-largest country. Australia is the oldest, flattest, and driest inhabited continent, with the least fertile soils. It is a megadiverse country, and its size gives it a wide variety of landscapes and climates, with deserts in the centre, tropical rainforests in the north-east, and mountain ranges in the south-east.\\nIndigenous Australians have inhabited the continent for approximately 65,000 years. The European maritime exploration of Australia commenced in the early 17th century with the arrival of Dutch explorers. In 1770, Australia's eastern half was claimed by Great Britain and initially settled through penal transportation to the colony of New South Wales from 26 January 1788, a date which became Australia's national day. The European population grew steadily in subsequent decades, and by the time of an 1850s gold rush, most of the continent had been explored by European settlers and an additional five self-governing crown colonies established. On 1 January 1901, the six colonies federated, forming the Commonwealth of Australia. Australia has since maintained a stable liberal democratic political system and wealthy market economy.\\nPolitically, Australia is a federal parliamentary constitutional monarchy, comprising six states and ten territories. Australia's population of nearly 26 million is highly urbanised and heavily concentrated on the eastern seaboard. Canberra is the nation's capital, while the five largest cities are Sydney, Melbourne, Brisbane, Perth, and Adelaide. Australia's demography has been shaped by centuries of immigration: immigrants account for 30% of the country's population, and almost half of Australians have at least one parent born overseas. Australia's abundant natural resources and well-developed international trade relations are crucial to the country's economy, which generates its income from various sources including services, mining exports, banking, manufacturing, agriculture and international education.\\nAustralia is a highly developed country with a high-income economy; it has the world's thirteenth-largest economy, tenth-highest per capita income and eighth-highest Human Development Index. Australia is a regional power, and has the world's thirteenth-highest military expenditure. Australia ranks amongst the highest in the world for quality of life, democracy, health, education, economic freedom, civil liberties, safety, and political rights, with all its major cities faring exceptionally in global comparative livability surveys. It is a member of international groupings including the United Nations, the G20, the OECD, the WTO, ANZUS, AUKUS, Five Eyes, the Quad, APEC, the Pacific Islands Forum, the Pacific Community and the Commonwealth of Nations.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be08b4e1-d68b-4665-bf38-5f3930242c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(raw_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0f2b2a-bf96-4ac3-86fb-b976aa706a62",
   "metadata": {},
   "source": [
    "## Sentence splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c171d2d2-35fc-4061-8c61-d894c73aae9a",
   "metadata": {},
   "source": [
    "Splitting text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4e6f49-4d2d-4a64-85f3-99c6a4d5e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78956490-64c6-42dc-8de3-21b050e3da81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenize?  # uncomment this line to see the documentation of `sent_tokenize'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0414b145-56b2-437d-aa71-ce41432391ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08169b36-63ac-49b2-a196-8cfb2137e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = sent_tokenize(raw_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3602844-7644-4f34-b963-307ca9536a11",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'There are {len(sentences)} sentences')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d76311-bf52-4b20-ba8c-19d65b763247",
   "metadata": {},
   "source": [
    "Use the first few sentences to demonstrate text pre-processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f283e5d-cbbc-413f-b4af-210b6803e5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ' '.join(sentences[:7])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66bc6a-cd25-4550-a61e-35a6a1dd5342",
   "metadata": {},
   "source": [
    "## Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ede3f5c-3d38-43ee-b0bc-2180b39dadd4",
   "metadata": {},
   "source": [
    "Dividing a string into a list of tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9598eb45-0690-4da1-acdc-06c0153e5747",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ae93eb-ab29-49c1-9df6-25f1c433bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_tokenize?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bede39-bc2d-4024-816e-eea39bb1d7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = word_tokenize(text)\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b4a093f-f14d-4629-b64c-ed193f2ba349",
   "metadata": {},
   "source": [
    "The top-10 most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfc7652-015c-4598-ac19-fc95a5b9b758",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(tokens).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8392f0a-a6d6-40b3-a216-b2e24e00c4b9",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Try [other tokenisers provided by NLTK](https://www.nltk.org/api/nltk.tokenize.html) (e.g. RegexpTokenizer, WhitespaceTokenizer, WordPunctTokenizer etc.) and compare their outputs. \n",
    "\n",
    "What are the differences and how can we choose the best tokeniser for a task?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "553a3c1a-31ef-44f6-95ed-b4825f65a4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.tokenize import WhitespaceTokenizer\n",
    "\n",
    "# tokeniser = WhitespaceTokenizer()\n",
    "# tokeniser.tokenize(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85c070b-ae72-46aa-a6b5-580aac52ffed",
   "metadata": {},
   "source": [
    "## Removing punctuation and stop words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7649191b-f526-4862-9ad9-adc3cf9e0f4e",
   "metadata": {},
   "source": [
    "Stopwords and punctuation are usually not helpful for many IR tasks, and removing them can reduce the number of tokens we need to process. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d509dc6f-28f6-4de3-a729-30fb5871741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0bc9103-97b8-430f-864c-9868bcdb0575",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0981b581-feaf-4ade-8637-d59282f8032b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_en = set(stopwords.words('english'))\n",
    "# stopwords_en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f544bef-dd26-4fca-948d-2d10187b86df",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens[:] = [w for w in tokens if w not in string.punctuation and w not in stopwords_en]\n",
    "# tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96b249d-d117-4ab1-b95a-ae2412b033d5",
   "metadata": {},
   "source": [
    "The top-10 most common tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f7ed35-78b5-4a31-a159-a0593706ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(tokens).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a02d0a-20a0-4950-98fc-0ae5184686d2",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Will we get a different set of tokens if we lower casing all words before removing stopwords? What are the potential problems by doing that?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95872ec7-9e27-43ab-bd8e-37d71ca58433",
   "metadata": {},
   "source": [
    "## Stemming or Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4003f2e9-d5c5-4a17-be0d-25bb5f21871e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "# from nltk.stem import SnowballStemmer, RegexpStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ec654e-ed6d-4da4-b5ac-4174687bd5fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac01896-822c-4c8b-bf05-9eb42ec4f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_stem = [stemmer.stem(w) for w in tokens]\n",
    "# tokens_stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d37d9d58-6a85-475f-8036-d0fc712a09f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(tokens_stem).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00477ff9-4273-4696-98c4-b5a6a4f39911",
   "metadata": {},
   "source": [
    "Lemmatisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "637e611d-8d23-4913-b60c-0160bdbf4d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3e9018-4770-4eac-bfaf-ec6f8fbbf2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869121b8-512a-406f-a87c-21e47ded0321",
   "metadata": {},
   "source": [
    "POS tagging for lemmatisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2e9325-251b-47b2-9833-0e13f7d6f656",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('averaged_perceptron_tagger')\n",
    "tags = nltk.pos_tag(tokens)\n",
    "# tags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4baddbec-df26-497f-9dde-1adddb649d7f",
   "metadata": {},
   "source": [
    "Convert the pos tags to the [four syntactic categories that wordnet recognizes](https://wordnet.princeton.edu/documentation/wndb5wn)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f05f26f-a383-444e-88e3-e885b91d39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_tag = lambda t: 'a' if t == 'j' else (t if t in ['n', 'v', 'r'] else 'n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df130d-6918-4ca6-a0c2-b859f75843ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ec851e-65c4-412d-8a5f-ad3277ade474",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_lemma = [lemmatizer.lemmatize(tokens[i].lower(), wordnet_tag(tags[i][1][0].lower())) for i in range(len(tokens))]\n",
    "# tokens_lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e901e5ea-1537-4def-a5c3-506b2e540e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Counter(tokens_lemma).most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f869e3c1-e510-4166-be69-34a212dc20b4",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Compare the results of stemming and lemmatisation. Can you see the differences and the potential problems with stemming and lemmatisation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "2e43985ea85cc7940c7a6e3f1b028a8ce6fce476b06597692744fbe9b068c3a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
